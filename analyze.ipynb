{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Imagens Sentinel para o Protótipo NAIÁ\n",
    "\n",
    "Este notebook analisa as imagens Sentinel-1 (VV/VH) e Sentinel-2 (RGB+NIR) recortadas por setores censitários urbanos de Barão Geraldo, Campinas (SP), no contexto do Hackathon CopernicusLAC Panamá 2025 (Dia 1, 21:09, 29/07/2025, -03). O objetivo é:\n",
    "1. Calcular métricas por setor censitário:\n",
    "   - **Sentinel-1**: Backscatter médio (VV e VH) em dB.\n",
    "   - **Sentinel-2**: NDVI médio (usando bandas NIR e Red).\n",
    "2. Salvar resultados em `data/processed/metrics.csv`.\n",
    "3. Gerar gráficos de validação (histogramas de NDVI e backscatter).\n",
    "\n",
    "## Configuração\n",
    "- **Ambiente**: `naia-env` (Python 3.12.7).\n",
    "- **Repositório**: `/home/lorhan/git/CorpenicusHackthon/`.\n",
    "- **Entradas**:\n",
    "  - `data/processed/s1_setor_<CD_SETOR>.tiff` (Sentinel-1, VV/VH, 2 bandas).\n",
    "  - `data/processed/s2_setor_<CD_SETOR>.tiff` (Sentinel-2, RGB+NIR, 4 bandas).\n",
    "  - `data/area_prova_barao.geojson` (setores censitários).\n",
    "- **Saídas**:\n",
    "  - `data/processed/metrics.csv`: Tabela com `CD_SETOR`, `VV_mean_dB`, `VH_mean_dB`, `NDVI_mean`.\n",
    "  - `data/processed/ndvi_histogram.png`: Histograma de NDVI médio.\n",
    "  - `data/processed/vv_histogram.png`: Histograma de backscatter VV médio.\n",
    "  - `data/processed/vh_histogram.png`: Histograma de backscatter VH médio.\n",
    "\n",
    "## Pré-requisitos\n",
    "1. Ative o ambiente: `source naia-env/bin/activate`.\n",
    "2. Instale dependências:\n",
    "   ```bash\n",
    "   pip install geopandas rasterio matplotlib pandas numpy\n",
    "   pip freeze > requirements.txt\n",
    "   ```\n",
    "3. Execute `preprocess.ipynb` para gerar os TIFFs recortados.\n",
    "4. Verifique a existência de `data/area_prova_barao.geojson`.\n",
    "5. Execute as células sequencialmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# Configurar diretórios\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "print('✓ Diretório data/processed/ criado ou já existente')\n",
    "\n",
    "# Definir caminhos\n",
    "sectors_path = 'data/area_prova_barao.geojson'\n",
    "s1_pattern = 'data/processed/s1_setor_*.tiff'\n",
    "s2_pattern = 'data/processed/s2_setor_*.tiff'\n",
    "\n",
    "# Verificar arquivos de entrada\n",
    "print('\\n--- Verificando arquivos de entrada ---')\n",
    "s1_files = glob.glob(s1_pattern)\n",
    "s2_files = glob.glob(s2_pattern)\n",
    "print(f'✓ Encontrados {len(s1_files)} arquivos Sentinel-1 recortados')\n",
    "print(f'✓ Encontrados {len(s2_files)} arquivos Sentinel-2 recortados')\n",
    "if os.path.exists(sectors_path):\n",
    "    size_mb = os.path.getsize(sectors_path) / (1024 * 1024)\n",
    "    print(f'✓ {sectors_path} ({size_mb:.1f} MB)')\n",
    "else:\n",
    "    print(f'❌ {sectors_path} não encontrado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento dos Setores Censitários\n",
    "\n",
    "Carregamos `data/area_prova_barao.geojson` e filtramos setores com TIFFs disponíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sectors_gdf = gpd.read_file(sectors_path)\n",
    "    print(f'✓ GeoJSON de setores carregado: {len(sectors_gdf)} setores censitários')\n",
    "    print(f'  Colunas disponíveis: {list(sectors_gdf.columns)}')\n",
    "    if 'CD_SETOR' not in sectors_gdf.columns:\n",
    "        raise ValueError('Coluna CD_SETOR não encontrada no GeoJSON')\n",
    "    # Filtrar setores urbanos com área <= 1.0 km²\n",
    "    sectors_gdf_urban = sectors_gdf[(sectors_gdf['SITUACAO'] == 'Urbana') & (sectors_gdf['AREA_KM2'] <= 1.0)]\n",
    "    print(f'✓ Setores filtrados: {len(sectors_gdf_urban)} setores urbanos com área ≤ 1.0 km²')\n",
    "    if len(sectors_gdf_urban) == 0:\n",
    "        raise ValueError('Nenhum setor urbano encontrado após filtro')\n",
    "    # Extrair IDs de setores com TIFFs disponíveis\n",
    "    s1_ids = {os.path.basename(f).replace('s1_setor_', '').replace('.tiff', '') for f in s1_files}\n",
    "    s2_ids = {os.path.basename(f).replace('s2_setor_', '').replace('.tiff', '') for f in s2_files}\n",
    "    sector_ids = s1_ids.intersection(s2_ids)  # Setores com ambos S1 e S2\n",
    "    print(f'✓ IDs de setores com TIFFs disponíveis: {len(sector_ids)}')\n",
    "    # Filtrar GeoDataFrame para setores com TIFFs\n",
    "    sectors_gdf_urban = sectors_gdf_urban[sectors_gdf_urban['CD_SETOR'].astype(str).isin(sector_ids)]\n",
    "    print(f'✓ Setores filtrados com TIFFs: {len(sectors_gdf_urban)}')\n",
    "except Exception as e:\n",
    "    print(f'❌ Erro ao carregar {sectors_path}: {e}')\n",
    "    sectors_gdf_urban = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cálculo das Métricas por Setor\n",
    "\n",
    "Calculamos o backscatter médio (VV e VH) para Sentinel-1 e o NDVI médio para Sentinel-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(s1_files, s2_files, sector_ids):\n",
    "    \"\"\"Calcula métricas por setor censitário.\"\"\"\n",
    "    metrics = []\n",
    "    s1_files_set = set(s1_files)\n",
    "    s2_files_set = set(s2_files)\n",
    "    for cd_setor in sector_ids:\n",
    "        s1_file = f'data/processed/s1_setor_{cd_setor}.tiff'\n",
    "        s2_file = f'data/processed/s2_setor_{cd_setor}.tiff'\n",
    "        metric = {'CD_SETOR': cd_setor}\n",
    "\n",
    "        # Processar Sentinel-1 (VV/VH)\n",
    "        if s1_file in s1_files_set:\n",
    "            try:\n",
    "                with rasterio.open(s1_file) as src:\n",
    "                    data = src.read()\n",
    "                    if data.shape[0] >= 2:  # VV e VH\n",
    "                        vv = data[0]\n",
    "                        vh = data[1]\n",
    "                        # Converter para dB (log10)\n",
    "                        vv_db = 10 * np.log10(vv + 1e-10)\n",
    "                        vh_db = 10 * np.log10(vh + 1e-10)\n",
    "                        # Médias, ignorando zeros\n",
    "                        vv_mean = np.nanmean(vv_db[vv_db > -100]) if np.any(vv_db > -100) else np.nan\n",
    "                        vh_mean = np.nanmean(vh_db[vh_db > -100]) if np.any(vh_db > -100) else np.nan\n",
    "                        metric['VV_mean_dB'] = vv_mean\n",
    "                        metric['VH_mean_dB'] = vh_mean\n",
    "                        print(f'✓ Processado S1: {cd_setor} (VV={vv_mean:.2f} dB, VH={vh_mean:.2f} dB)')\n",
    "                    else:\n",
    "                        print(f'⚠️ {s1_file} tem menos de 2 bandas')\n",
    "                        metric['VV_mean_dB'] = np.nan\n",
    "                        metric['VH_mean_dB'] = np.nan\n",
    "            except Exception as e:\n",
    "                print(f'❌ Erro ao processar {s1_file}: {e}')\n",
    "                metric['VV_mean_dB'] = np.nan\n",
    "                metric['VH_mean_dB'] = np.nan\n",
    "        else:\n",
    "            metric['VV_mean_dB'] = np.nan\n",
    "            metric['VH_mean_dB'] = np.nan\n",
    "\n",
    "        # Processar Sentinel-2 (NDVI)\n",
    "        if s2_file in s2_files_set:\n",
    "            try:\n",
    "                with rasterio.open(s2_file) as src:\n",
    "                    data = src.read()\n",
    "                    if data.shape[0] >= 4:  # R, G, B, NIR\n",
    "                        red = data[0].astype(float)\n",
    "                        nir = data[3].astype(float)\n",
    "                        # Calcular NDVI: (NIR - Red) / (NIR + Red)\n",
    "                        ndvi = (nir - red) / (nir + red + 1e-10)\n",
    "                        # Média, ignorando valores inválidos\n",
    "                        ndvi_mean = np.nanmean(ndvi[(ndvi >= -1) & (ndvi <= 1)]) if np.any((ndvi >= -1) & (ndvi <= 1)) else np.nan\n",
    "                        metric['NDVI_mean'] = ndvi_mean\n",
    "                        print(f'✓ Processado S2: {cd_setor} (NDVI={ndvi_mean:.3f})')\n",
    "                    else:\n",
    "                        print(f'⚠️ {s2_file} tem menos de 4 bandas')\n",
    "                        metric['NDVI_mean'] = np.nan\n",
    "            except Exception as e:\n",
    "                print(f'❌ Erro ao processar {s2_file}: {e}')\n",
    "                metric['NDVI_mean'] = np.nan\n",
    "        else:\n",
    "            metric['NDVI_mean'] = np.nan\n",
    "\n",
    "        metrics.append(metric)\n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "if sectors_gdf_urban is not None:\n",
    "    print('\\n--- Calculando métricas por setor ---')\n",
    "    metrics_df = calculate_metrics(s1_files, s2_files, sector_ids)\n",
    "    output_csv = 'data/processed/metrics.csv'\n",
    "    metrics_df.to_csv(output_csv, index=False)\n",
    "    print(f'✓ Métricas salvas em {output_csv}')\n",
    "else:\n",
    "    print('❌ Pulando cálculo de métricas devido a falha no carregamento dos setores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validação com Gráficos\n",
    "\n",
    "Geramos histogramas para visualizar a distribuição de NDVI e backscatter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'metrics_df' in locals() and not metrics_df.empty:\n",
    "    # Histograma de NDVI\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(metrics_df['NDVI_mean'].dropna(), bins=20, color='green', alpha=0.7)\n",
    "    plt.title('Distribuição de NDVI Médio por Setor Censitário', fontsize=14)\n",
    "    plt.xlabel('NDVI Médio')\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('data/processed/ndvi_histogram.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print('✓ Histograma de NDVI salvo em data/processed/ndvi_histogram.png')\n",
    "\n",
    "    # Histograma de VV (Sentinel-1)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(metrics_df['VV_mean_dB'].dropna(), bins=20, color='blue', alpha=0.7)\n",
    "    plt.title('Distribuição de Backscatter VV Médio (dB) por Setor Censitário', fontsize=14)\n",
    "    plt.xlabel('Backscatter VV Médio (dB)')\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('data/processed/vv_histogram.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print('✓ Histograma de VV salvo em data/processed/vv_histogram.png')\n",
    "\n",
    "    # Histograma de VH (Sentinel-1)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(metrics_df['VH_mean_dB'].dropna(), bins=20, color='purple', alpha=0.7)\n",
    "    plt.title('Distribuição de Backscatter VH Médio (dB) por Setor Censitário', fontsize=14)\n",
    "    plt.xlabel('Backscatter VH Médio (dB)')\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('data/processed/vh_histogram.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print('✓ Histograma de VH salvo em data/processed/vh_histogram.png')\n",
    "else:\n",
    "    print('❌ Pulando gráficos devido a falha no cálculo de métricas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Resumo da Execução\n",
    "\n",
    "Resumimos o status da análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*50)\n",
    "print('📋 RESUMO DA EXECUÇÃO')\n",
    "print('='*50)\n",
    "print(f'✓ Setores urbanos processados: {len(sectors_gdf_urban) if sectors_gdf_urban is not None else 0}')\n",
    "print(f'✓ Arquivos Sentinel-1 processados: {len(s1_files)}')\n",
    "print(f'✓ Arquivos Sentinel-2 processados: {len(s2_files)}')\n",
    "if 'metrics_df' in locals():\n",
    "    print(f'✓ Setores com métricas calculadas: {len(metrics_df)}')\n",
    "    print(f'✓ Setores com TIFFs ausentes: {len(sector_ids) - len(metrics_df[metrics_df[[\"VV_mean_dB\", \"VH_mean_dB\", \"NDVI_mean\"]].notna().all(axis=1)])}')\n",
    "    print(f'✓ Média NDVI: {metrics_df[\"NDVI_mean\"].mean():.3f}')\n",
    "    print(f'✓ Média VV (dB): {metrics_df[\"VV_mean_dB\"].mean():.2f}')\n",
    "    print(f'✓ Média VH (dB): {metrics_df[\"VH_mean_dB\"].mean():.2f}')\n",
    "\n",
    "print('\\n🗂️ ARQUIVOS GERADOS:')\n",
    "for file in glob.glob('data/processed/*.csv') + glob.glob('data/processed/*_histogram.png'):\n",
    "    if os.path.exists(file):\n",
    "        print(f'  ✓ {file} (Tamanho: {os.path.getsize(file) / 1024 / 1024:.2f} MB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Próximos Passos\n",
    "\n",
    "- **Validação**: Abra `data/processed/metrics.csv` para verificar as métricas. Inspecione `data/processed/ndvi_histogram.png`, `data/processed/vv_histogram.png`, e `data/processed/vh_histogram.png` para validar as distribuições.\n",
    "- **Solução de Problemas**:\n",
    "  - Se setores ausentes forem críticos, verifique os limites das imagens:\n",
    "    ```python\n",
    "    import rasterio\n",
    "    for path in ['data/sentinel1_unicamp.tiff', 'data/sentinel2_unicamp.tiff']:\n",
    "        with rasterio.open(path) as src:\n",
    "            print(f'{path}: Bounds={src.bounds}, CRS={src.crs}')\n",
    "    ```\n",
    "    Reexecute `ingest_sentinel.ipynb` com uma bounding box maior, se necessário.\n",
    "  - Para validar um TIFF:\n",
    "    ```python\n",
    "    with rasterio.open('data/processed/s1_setor_350950210000110.tiff') as src:\n",
    "        print(f'Dimensões: {src.width}x{src.height}, Bandas: {src.count}')\n",
    "    ```\n",
    "- **Commit**:\n",
    "   ```bash\n",
    "   git add analyze.ipynb data/processed/metrics.csv data/processed/*_histogram.png\n",
    "   git commit -m \"Análise: corrigido para processar apenas setores com TIFFs disponíveis\"\n",
    "   git push origin main\n",
    "   ```\n",
    "- **Cronograma**: Conclua até 23:59 (29/07/2025). Solicite o próximo notebook (ex.: integração com dados climáticos) se desejar avançar.\n",
    "- **Dicas**:\n",
    "  - Para dados climáticos, instale:\n",
    "    ```bash\n",
    "    pip install xarray netCDF4 cdsapi\n",
    "    ```\n",
    "  - Exemplo de mapa de NDVI:\n",
    "    ```python\n",
    "    with rasterio.open('data/processed/s2_setor_350950210000110.tiff') as src:\n",
    "        red, nir = src.read(1), src.read(4)\n",
    "        ndvi = (nir - red) / (nir + red + 1e-10)\n",
    "        plt.imshow(ndvi, cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "        plt.colorbar(label='NDVI')\n",
    "        plt.show()\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naia-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}