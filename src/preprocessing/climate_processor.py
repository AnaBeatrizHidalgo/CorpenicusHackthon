# Importa√ß√µes
import os
import cdsapi
import xarray as xr
import geopandas as gpd
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.interpolate import RegularGridInterpolator
from shapely.geometry import box

# Configurar diret√≥rios
os.makedirs('data/processed', exist_ok=True)
print('‚úì Diret√≥rio data/processed/ criado ou j√° existente')

# Verificar vers√£o do cdsapi
import cdsapi
print(f'‚úì Vers√£o do cdsapi: {cdsapi.__version__}')

# Definir caminhos
sectors_path = 'data/area_prova_barao.geojson'
metrics_path = 'data/processed/metrics.csv'
climate_path = 'data/processed/data_0.nc'
output_csv = 'data/processed/climate_metrics.csv'

# Verificar arquivos de entrada
print('\n--- Verificando arquivos de entrada ---')
for path in [sectors_path, metrics_path]:
    if os.path.exists(path):
        size_mb = os.path.getsize(path) / (1024 * 1024)
        print(f'‚úì {path} ({size_mb:.1f} MB)')
    else:
        print(f'‚ùå {path} n√£o encontrado')
try:
    c = cdsapi.Client()
    c.retrieve(
        'reanalysis-era5-land',
        {
            'variable': ['total_precipitation', '2m_temperature'],
            'year': '2025',
            'month': '06',
            'day': [str(i).zfill(2) for i in range(1, 31)],
            'time': ['00:00', '06:00', '12:00', '18:00'],
            'area': [-22.75, -47.15, -22.95, -46.95],  # [N, W, S, E]
            'format': 'netcdf'
        },
        'data/processed/era5_climate.nc')
    print(f'‚úì Dados clim√°ticos salvos em data/processed/era5_climate.nc')
except Exception as e:
    print(f'‚ùå Erro ao baixar dados ERA5-Land: {e}')

try:
    # Verificar NetCDF
    if os.path.exists(climate_path):
        ds = xr.open_dataset(climate_path, engine='netcdf4')
        print(f'‚úì Coordenadas do NetCDF:')
        print(f'  Latitude: {ds['latitude'].values}')
        print(f'  Longitude: {ds['longitude'].values}')
        print(f'  Bounding box: (min_lon, min_lat, max_lon, max_lat) = '
              f'({ds['longitude'].min().values}, {ds['latitude'].min().values}, '
              f'{ds['longitude'].max().values}, {ds['latitude'].max().values})')
        print(f'  N√∫mero de pontos: {len(ds['latitude']) * len(ds['longitude'])}')

        # Verificar cobertura dos setores
        gdf = gpd.read_file(sectors_path)
        gdf = gdf[(gdf['SITUACAO'] == 'Urbana') & (gdf['AREA_KM2'] <= 1.0)]
        bounds = gdf.bounds
        sectors_bbox = (bounds['minx'].min(), bounds['miny'].min(), bounds['maxx'].max(), bounds['maxy'].max())
        print(f'\n‚úì Bounding box dos setores censit√°rios:')
        print(f'  (min_lon, min_lat, max_lon, max_lat) = {sectors_bbox}')
        print(f'\n‚úì Verifica√ß√£o de cobertura:')
        if (ds['longitude'].min() <= sectors_bbox[0] and ds['longitude'].max() >= sectors_bbox[2] and
            ds['latitude'].min() <= sectors_bbox[1] and ds['latitude'].max() >= sectors_bbox[3]):
            print('  ‚úì NetCDF cobre completamente a √°rea dos setores')
        else:
            print('  ‚ö†Ô∏è NetCDF n√£o cobre completamente a √°rea dos setores')
        ds.close()
    else:
        print(f'‚ùå {climate_path} n√£o encontrado')

    # Resumo dos setores
    print(f'\n‚úì Total de setores urbanos: {len(gdf)}')
except Exception as e:
    print(f'‚ùå Erro ao verificar coordenadas: {e}')
def aggregate_climate_by_sector(climate_path, sectors_path):
    """Agrega dados clim√°ticos por setor censit√°rio."""
    try:
        # Verificar arquivo NetCDF
        if not os.path.exists(climate_path):
            raise FileNotFoundError(f'{climate_path} n√£o encontrado')
        with xr.open_dataset(climate_path, engine='netcdf4') as ds:
            print(f'‚úì Arquivo {climate_path} v√°lido, vari√°veis: {list(ds.variables)}')

        # Carregar setores censit√°rios
        gdf = gpd.read_file(sectors_path)
        gdf = gdf[(gdf['SITUACAO'] == 'Urbana') & (gdf['AREA_KM2'] <= 1.0)]
        print(f'‚úì Carregados {len(gdf)} setores urbanos')

        # Carregar dados clim√°ticos
        ds = xr.open_dataset(climate_path, engine='netcdf4')
        # Corrigir nomes de vari√°veis
        ds['total_precipitation'] = ds['tp'] * 1000  # metros para mm
        ds['t2m'] = ds['t2m'] - 273.15  # Kelvin para ¬∞C

        # M√©dia mensal por pixel
        precip_mean = ds['total_precipitation'].mean(dim='valid_time')
        temp_mean = ds['t2m'].mean(dim='valid_time')

        # Configurar interpoladores
        lat, lon = ds['latitude'].values, ds['longitude'].values
        precip_interp = RegularGridInterpolator(
            (lat, lon), precip_mean.values,
            method='nearest', bounds_error=False, fill_value=np.nan
        )
        temp_interp = RegularGridInterpolator(
            (lat, lon), temp_mean.values,
            method='nearest', bounds_error=False, fill_value=np.nan
        )

        climate_metrics = []
        sectors_with_data = 0
        for idx, row in gdf.iterrows():
            cd_setor = int(row['CD_SETOR'])  # Converter para int64
            geom = row['geometry']
            bounds = geom.bounds  # (minx, miny, maxx, maxy)
            # M√°scara ajustada para latitude decrescente
            mask = (ds['longitude'] >= bounds[0]) & (ds['longitude'] <= bounds[2]) & \
                   (ds['latitude'] >= bounds[3]) & (ds['latitude'] <= bounds[1])
            if mask.any():
                precip = precip_mean.where(mask, drop=True).mean().values
                temp = temp_mean.where(mask, drop=True).mean().values
                if not np.isnan(precip) and not np.isnan(temp):
                    sectors_with_data += 1
                climate_metrics.append({
                    'CD_SETOR': cd_setor,
                    'precip_mean_mm': float(precip) if not np.isnan(precip) else np.nan,
                    'temp_mean_C': float(temp) if not np.isnan(temp) else np.nan
                })
                print(f'‚úì Processado setor {cd_setor}: Precip={precip:.2f} mm, Temp={temp:.2f} ¬∞C')
            else:
                # Fallback: usar interpola√ß√£o no centr√≥ide do setor
                centroid = geom.centroid
                precip = precip_interp((centroid.y, centroid.x))
                temp = temp_interp((centroid.y, centroid.x))
                if not np.isnan(precip) and not np.isnan(temp):
                    sectors_with_data += 1
                climate_metrics.append({
                    'CD_SETOR': cd_setor,
                    'precip_mean_mm': float(precip) if not np.isnan(precip) else np.nan,
                    'temp_mean_C': float(temp) if not np.isnan(temp) else np.nan
                })
                print(f'‚ö†Ô∏è Setor {cd_setor} fora da grade; usado interpola√ß√£o: Precip={precip:.2f} mm, Temp={temp:.2f} ¬∞C')
        print(f'\n‚úì Total de setores com dados v√°lidos: {sectors_with_data}/{len(gdf)}')
        climate_df = pd.DataFrame(climate_metrics)
        climate_df['CD_SETOR'] = climate_df['CD_SETOR'].astype('int64')  # Garantir tipo int64
        return climate_df
    except Exception as e:
        print(f'‚ùå Erro ao agregar dados clim√°ticos: {e}')
        return None

if os.path.exists(climate_path) and os.path.exists(sectors_path):
    print('\n--- Agregando dados clim√°ticos por setor ---')
    climate_df = aggregate_climate_by_sector(climate_path, sectors_path)
    if climate_df is not None:
        climate_df.to_csv(output_csv, index=False)
        print(f'‚úì M√©tricas clim√°ticas salvas em {output_csv}')
else:
    print('‚ùå Pulando agrega√ß√£o devido a arquivos ausentes')

if 'climate_df' in locals() and os.path.exists(metrics_path):
    print('\n--- Mesclando e calculando correla√ß√µes ---')
    metrics_df = pd.read_csv(metrics_path)
    # Verificar tipos de dados
    print(f'‚úì Tipo de CD_SETOR em metrics_df: {metrics_df['CD_SETOR'].dtype}')
    print(f'‚úì Tipo de CD_SETOR em climate_df: {climate_df['CD_SETOR'].dtype}')
    # Garantir que CD_SETOR em metrics_df seja int64
    metrics_df['CD_SETOR'] = metrics_df['CD_SETOR'].astype('int64')
    merged_df = metrics_df.merge(climate_df, on='CD_SETOR', how='left')
    merged_df.to_csv(output_csv, index=False)
    print(f'‚úì Dados mesclados salvos em {output_csv}')

    # Calcular correla√ß√µes
    correlations = merged_df[['NDVI_mean', 'VV_mean_dB', 'VH_mean_dB', 'precip_mean_mm', 'temp_mean_C']].corr()
    print('\nCorrela√ß√µes:')
    print(correlations)

    # Gr√°fico: NDVI vs. Precipita√ß√£o
    plt.figure(figsize=(10, 6))
    plt.scatter(merged_df['precip_mean_mm'], merged_df['NDVI_mean'], color='green', alpha=0.6)
    plt.title('Correla√ß√£o: NDVI M√©dio vs. Precipita√ß√£o M√©dia', fontsize=14)
    plt.xlabel('Precipita√ß√£o M√©dia (mm)')
    plt.ylabel('NDVI M√©dio')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig('data/processed/ndvi_precip_correlation.png', dpi=300, bbox_inches='tight')
    plt.show()
    print('‚úì Gr√°fico salvo em data/processed/ndvi_precip_correlation.png')

    # Gr√°fico: NDVI vs. Temperatura
    plt.figure(figsize=(10, 6))
    plt.scatter(merged_df['temp_mean_C'], merged_df['NDVI_mean'], color='blue', alpha=0.6)
    plt.title('Correla√ß√£o: NDVI M√©dio vs. Temperatura M√©dia', fontsize=14)
    plt.xlabel('Temperatura M√©dia (¬∞C)')
    plt.ylabel('NDVI M√©dio')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig('data/processed/ndvi_temp_correlation.png', dpi=300, bbox_inches='tight')
    plt.show()
    print('‚úì Gr√°fico salvo em data/processed/ndvi_temp_correlation.png')
else:
    print('‚ùå Pulando mesclagem devido a dados ausentes')
print('\n' + '='*50)
print('üìã RESUMO DA EXECU√á√ÉO')
print('='*50)
if 'climate_df' in locals():
    print(f'‚úì Setores com m√©tricas clim√°ticas: {len(climate_df)}')
    print(f'‚úì Setores com dados v√°lidos: {len(climate_df[climate_df[["precip_mean_mm", "temp_mean_C"]].notna().all(axis=1)])}')
    print(f'‚úì M√©dia Precipita√ß√£o: {climate_df["precip_mean_mm"].mean():.2f} mm')
    print(f'‚úì M√©dia Temperatura: {climate_df["temp_mean_C"].mean():.2f} ¬∞C')
if 'merged_df' in locals():
    print(f'‚úì Correla√ß√£o NDVI-Precipita√ß√£o: {correlations.loc["NDVI_mean", "precip_mean_mm"]:.3f}')
    print(f'‚úì Correla√ß√£o NDVI-Temperatura: {correlations.loc["NDVI_mean", "temp_mean_C"]:.3f}')

print('\nüóÇÔ∏è ARQUIVOS GERADOS:')
import glob
for file in glob.glob('data/processed/*climate*.csv') + glob.glob('data/processed/*correlation*.png'):
    if os.path.exists(file):
        print(f'  ‚úì {file} (Tamanho: {os.path.getsize(file) / 1024 / 1024:.2f} MB)')