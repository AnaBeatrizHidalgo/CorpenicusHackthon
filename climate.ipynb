{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integra√ß√£o de Dados Clim√°ticos para o Prot√≥tipo NAI√Å\n",
    "\n",
    "Este notebook integra dados clim√°ticos do Copernicus Climate Data Store (CDS) ao projeto NAI√Å, no contexto do Hackathon CopernicusLAC Panam√° 2025 (Dia 1, 23:34, 29/07/2025, -03). O objetivo √©:\n",
    "1. Baixar dados ERA5-Land (precipita√ß√£o total e temperatura a 2m) para Bar√£o Geraldo, Campinas (SP), na bounding box `[-47.15, -22.75, -46.95, -22.95]`.\n",
    "2. Agregar m√©tricas clim√°ticas por setor censit√°rio usando `data/area_prova_barao.geojson`.\n",
    "3. Mesclar com m√©tricas de Sentinel-1 e Sentinel-2 (`data/processed/metrics.csv`) para correlacionar NDVI e backscatter com vari√°veis clim√°ticas.\n",
    "4. Gerar gr√°ficos de correla√ß√£o e salvar resultados em `data/processed/climate_metrics.csv`.\n",
    "\n",
    "## Configura√ß√£o\n",
    "- **Ambiente**: `naia-env` (Python 3.12.7).\n",
    "- **Reposit√≥rio**: `/home/lorhan/git/CorpenicusHackthon/`.\n",
    "- **Entradas**:\n",
    "  - `data/area_prova_barao.geojson`: Setores censit√°rios.\n",
    "  - `data/processed/metrics.csv`: M√©tricas de NDVI e backscatter.\n",
    "  - Dados ERA5-Land via CDSAPI: `data/processed/data_0.nc` (extra√≠do de um ZIP).\n",
    "- **Sa√≠das**:\n",
    "  - `data/processed/climate_metrics.csv`: M√©tricas clim√°ticas por setor (precipita√ß√£o m√©dia, temperatura m√©dia).\n",
    "  - `data/processed/ndvi_precip_correlation.png`: Gr√°fico de correla√ß√£o NDVI vs. precipita√ß√£o.\n",
    "  - `data/processed/ndvi_temp_correlation.png`: Gr√°fico de correla√ß√£o NDVI vs. temperatura.\n",
    "\n",
    "## Pr√©-requisitos\n",
    "1. Ative o ambiente: `source naia-env/bin/activate`.\n",
    "2. Instale depend√™ncias:\n",
    "   ```bash\n",
    "   pip install xarray netCDF4 cdsapi>=0.7.4 geopandas pandas numpy matplotlib scipy\n",
    "   pip freeze > requirements.txt\n",
    "   ```\n",
    "3. Configure a API CDSAPI:\n",
    "   - Crie `~/.cdsapirc` com suas credenciais do CDS ([cds.climate.copernicus.eu](https://cds.climate.copernicus.eu)):\n",
    "     ```bash\n",
    "     echo \"url: https://cds.climate.copernicus.eu/api/v2\" > ~/.cdsapirc\n",
    "     echo \"key: seu_uid:seu_api_key\" >> ~/.cdsapirc\n",
    "     ```\n",
    "4. Execute `ingest_sentinel.ipynb`, `preprocess.ipynb`, e `analyze.ipynb` para gerar `data/processed/metrics.csv`.\n",
    "5. Extraia `data_0.nc` do ZIP baixado pelo CDSAPI e coloque em `data/processed/`.\n",
    "6. Execute as c√©lulas sequencialmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√µes\n",
    "import os\n",
    "import cdsapi\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from shapely.geometry import box\n",
    "\n",
    "# Configurar diret√≥rios\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "print('‚úì Diret√≥rio data/processed/ criado ou j√° existente')\n",
    "\n",
    "# Verificar vers√£o do cdsapi\n",
    "import cdsapi\n",
    "print(f'‚úì Vers√£o do cdsapi: {cdsapi.__version__}')\n",
    "\n",
    "# Definir caminhos\n",
    "sectors_path = 'data/area_prova_barao.geojson'\n",
    "metrics_path = 'data/processed/metrics.csv'\n",
    "climate_path = 'data/processed/data_0.nc'\n",
    "output_csv = 'data/processed/climate_metrics.csv'\n",
    "\n",
    "# Verificar arquivos de entrada\n",
    "print('\\n--- Verificando arquivos de entrada ---')\n",
    "for path in [sectors_path, metrics_path]:\n",
    "    if os.path.exists(path):\n",
    "        size_mb = os.path.getsize(path) / (1024 * 1024)\n",
    "        print(f'‚úì {path} ({size_mb:.1f} MB)')\n",
    "    else:\n",
    "        print(f'‚ùå {path} n√£o encontrado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download de Dados Clim√°ticos\n",
    "\n",
    "Baixamos dados ERA5-Land (precipita√ß√£o total e temperatura a 2m) para a bounding box de Bar√£o Geraldo, per√≠odo de 01/06/2025 a 30/06/2025. A bounding box `[-47.15, -22.75, -46.95, -22.95]` foi validada para conter m√∫ltiplos pontos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    c = cdsapi.Client()\n",
    "    c.retrieve(\n",
    "        'reanalysis-era5-land',\n",
    "        {\n",
    "            'variable': ['total_precipitation', '2m_temperature'],\n",
    "            'year': '2025',\n",
    "            'month': '06',\n",
    "            'day': [str(i).zfill(2) for i in range(1, 31)],\n",
    "            'time': ['00:00', '06:00', '12:00', '18:00'],\n",
    "            'area': [-22.75, -47.15, -22.95, -46.95],  # [N, W, S, E]\n",
    "            'format': 'netcdf'\n",
    "        },\n",
    "        'data/processed/era5_climate.nc')\n",
    "    print(f'‚úì Dados clim√°ticos salvos em data/processed/era5_climate.nc')\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Erro ao baixar dados ERA5-Land: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verifica√ß√£o de Coordenadas\n",
    "\n",
    "Inspecionamos as coordenadas do NetCDF e dos setores para confirmar cobertura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Verificar NetCDF\n",
    "    if os.path.exists(climate_path):\n",
    "        ds = xr.open_dataset(climate_path, engine='netcdf4')\n",
    "        print(f'‚úì Coordenadas do NetCDF:')\n",
    "        print(f'  Latitude: {ds['latitude'].values}')\n",
    "        print(f'  Longitude: {ds['longitude'].values}')\n",
    "        print(f'  Bounding box: (min_lon, min_lat, max_lon, max_lat) = '\n",
    "              f'({ds['longitude'].min().values}, {ds['latitude'].min().values}, '\n",
    "              f'{ds['longitude'].max().values}, {ds['latitude'].max().values})')\n",
    "        print(f'  N√∫mero de pontos: {len(ds['latitude']) * len(ds['longitude'])}')\n",
    "\n",
    "        # Verificar cobertura dos setores\n",
    "        gdf = gpd.read_file(sectors_path)\n",
    "        gdf = gdf[(gdf['SITUACAO'] == 'Urbana') & (gdf['AREA_KM2'] <= 1.0)]\n",
    "        bounds = gdf.bounds\n",
    "        sectors_bbox = (bounds['minx'].min(), bounds['miny'].min(), bounds['maxx'].max(), bounds['maxy'].max())\n",
    "        print(f'\\n‚úì Bounding box dos setores censit√°rios:')\n",
    "        print(f'  (min_lon, min_lat, max_lon, max_lat) = {sectors_bbox}')\n",
    "        print(f'\\n‚úì Verifica√ß√£o de cobertura:')\n",
    "        if (ds['longitude'].min() <= sectors_bbox[0] and ds['longitude'].max() >= sectors_bbox[2] and\n",
    "            ds['latitude'].min() <= sectors_bbox[1] and ds['latitude'].max() >= sectors_bbox[3]):\n",
    "            print('  ‚úì NetCDF cobre completamente a √°rea dos setores')\n",
    "        else:\n",
    "            print('  ‚ö†Ô∏è NetCDF n√£o cobre completamente a √°rea dos setores')\n",
    "        ds.close()\n",
    "    else:\n",
    "        print(f'‚ùå {climate_path} n√£o encontrado')\n",
    "\n",
    "    # Resumo dos setores\n",
    "    print(f'\\n‚úì Total de setores urbanos: {len(gdf)}')\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Erro ao verificar coordenadas: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carregamento e Agrega√ß√£o por Setor\n",
    "\n",
    "Carregamos os dados clim√°ticos e agregamos m√©tricas (m√©dia mensal) por setor censit√°rio, com interpola√ß√£o como fallback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_climate_by_sector(climate_path, sectors_path):\n",
    "    \"\"\"Agrega dados clim√°ticos por setor censit√°rio.\"\"\"\n",
    "    try:\n",
    "        # Verificar arquivo NetCDF\n",
    "        if not os.path.exists(climate_path):\n",
    "            raise FileNotFoundError(f'{climate_path} n√£o encontrado')\n",
    "        with xr.open_dataset(climate_path, engine='netcdf4') as ds:\n",
    "            print(f'‚úì Arquivo {climate_path} v√°lido, vari√°veis: {list(ds.variables)}')\n",
    "\n",
    "        # Carregar setores censit√°rios\n",
    "        gdf = gpd.read_file(sectors_path)\n",
    "        gdf = gdf[(gdf['SITUACAO'] == 'Urbana') & (gdf['AREA_KM2'] <= 1.0)]\n",
    "        print(f'‚úì Carregados {len(gdf)} setores urbanos')\n",
    "\n",
    "        # Carregar dados clim√°ticos\n",
    "        ds = xr.open_dataset(climate_path, engine='netcdf4')\n",
    "        # Corrigir nomes de vari√°veis\n",
    "        ds['total_precipitation'] = ds['tp'] * 1000  # metros para mm\n",
    "        ds['t2m'] = ds['t2m'] - 273.15  # Kelvin para ¬∞C\n",
    "\n",
    "        # M√©dia mensal por pixel\n",
    "        precip_mean = ds['total_precipitation'].mean(dim='valid_time')\n",
    "        temp_mean = ds['t2m'].mean(dim='valid_time')\n",
    "\n",
    "        # Configurar interpoladores\n",
    "        lat, lon = ds['latitude'].values, ds['longitude'].values\n",
    "        precip_interp = RegularGridInterpolator(\n",
    "            (lat, lon), precip_mean.values,\n",
    "            method='nearest', bounds_error=False, fill_value=np.nan\n",
    "        )\n",
    "        temp_interp = RegularGridInterpolator(\n",
    "            (lat, lon), temp_mean.values,\n",
    "            method='nearest', bounds_error=False, fill_value=np.nan\n",
    "        )\n",
    "\n",
    "        climate_metrics = []\n",
    "        sectors_with_data = 0\n",
    "        for idx, row in gdf.iterrows():\n",
    "            cd_setor = int(row['CD_SETOR'])  # Converter para int64\n",
    "            geom = row['geometry']\n",
    "            bounds = geom.bounds  # (minx, miny, maxx, maxy)\n",
    "            # M√°scara ajustada para latitude decrescente\n",
    "            mask = (ds['longitude'] >= bounds[0]) & (ds['longitude'] <= bounds[2]) & \\\n",
    "                   (ds['latitude'] >= bounds[3]) & (ds['latitude'] <= bounds[1])\n",
    "            if mask.any():\n",
    "                precip = precip_mean.where(mask, drop=True).mean().values\n",
    "                temp = temp_mean.where(mask, drop=True).mean().values\n",
    "                if not np.isnan(precip) and not np.isnan(temp):\n",
    "                    sectors_with_data += 1\n",
    "                climate_metrics.append({\n",
    "                    'CD_SETOR': cd_setor,\n",
    "                    'precip_mean_mm': float(precip) if not np.isnan(precip) else np.nan,\n",
    "                    'temp_mean_C': float(temp) if not np.isnan(temp) else np.nan\n",
    "                })\n",
    "                print(f'‚úì Processado setor {cd_setor}: Precip={precip:.2f} mm, Temp={temp:.2f} ¬∞C')\n",
    "            else:\n",
    "                # Fallback: usar interpola√ß√£o no centr√≥ide do setor\n",
    "                centroid = geom.centroid\n",
    "                precip = precip_interp((centroid.y, centroid.x))\n",
    "                temp = temp_interp((centroid.y, centroid.x))\n",
    "                if not np.isnan(precip) and not np.isnan(temp):\n",
    "                    sectors_with_data += 1\n",
    "                climate_metrics.append({\n",
    "                    'CD_SETOR': cd_setor,\n",
    "                    'precip_mean_mm': float(precip) if not np.isnan(precip) else np.nan,\n",
    "                    'temp_mean_C': float(temp) if not np.isnan(temp) else np.nan\n",
    "                })\n",
    "                print(f'‚ö†Ô∏è Setor {cd_setor} fora da grade; usado interpola√ß√£o: Precip={precip:.2f} mm, Temp={temp:.2f} ¬∞C')\n",
    "        print(f'\\n‚úì Total de setores com dados v√°lidos: {sectors_with_data}/{len(gdf)}')\n",
    "        climate_df = pd.DataFrame(climate_metrics)\n",
    "        climate_df['CD_SETOR'] = climate_df['CD_SETOR'].astype('int64')  # Garantir tipo int64\n",
    "        return climate_df\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Erro ao agregar dados clim√°ticos: {e}')\n",
    "        return None\n",
    "\n",
    "if os.path.exists(climate_path) and os.path.exists(sectors_path):\n",
    "    print('\\n--- Agregando dados clim√°ticos por setor ---')\n",
    "    climate_df = aggregate_climate_by_sector(climate_path, sectors_path)\n",
    "    if climate_df is not None:\n",
    "        climate_df.to_csv(output_csv, index=False)\n",
    "        print(f'‚úì M√©tricas clim√°ticas salvas em {output_csv}')\n",
    "else:\n",
    "    print('‚ùå Pulando agrega√ß√£o devido a arquivos ausentes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mesclagem e Correla√ß√£o\n",
    "\n",
    "Mesclamos os dados clim√°ticos com `metrics.csv` e calculamos correla√ß√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'climate_df' in locals() and os.path.exists(metrics_path):\n",
    "    print('\\n--- Mesclando e calculando correla√ß√µes ---')\n",
    "    metrics_df = pd.read_csv(metrics_path)\n",
    "    # Verificar tipos de dados\n",
    "    print(f'‚úì Tipo de CD_SETOR em metrics_df: {metrics_df['CD_SETOR'].dtype}')\n",
    "    print(f'‚úì Tipo de CD_SETOR em climate_df: {climate_df['CD_SETOR'].dtype}')\n",
    "    # Garantir que CD_SETOR em metrics_df seja int64\n",
    "    metrics_df['CD_SETOR'] = metrics_df['CD_SETOR'].astype('int64')\n",
    "    merged_df = metrics_df.merge(climate_df, on='CD_SETOR', how='left')\n",
    "    merged_df.to_csv(output_csv, index=False)\n",
    "    print(f'‚úì Dados mesclados salvos em {output_csv}')\n",
    "\n",
    "    # Calcular correla√ß√µes\n",
    "    correlations = merged_df[['NDVI_mean', 'VV_mean_dB', 'VH_mean_dB', 'precip_mean_mm', 'temp_mean_C']].corr()\n",
    "    print('\\nCorrela√ß√µes:')\n",
    "    print(correlations)\n",
    "\n",
    "    # Gr√°fico: NDVI vs. Precipita√ß√£o\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(merged_df['precip_mean_mm'], merged_df['NDVI_mean'], color='green', alpha=0.6)\n",
    "    plt.title('Correla√ß√£o: NDVI M√©dio vs. Precipita√ß√£o M√©dia', fontsize=14)\n",
    "    plt.xlabel('Precipita√ß√£o M√©dia (mm)')\n",
    "    plt.ylabel('NDVI M√©dio')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('data/processed/ndvi_precip_correlation.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print('‚úì Gr√°fico salvo em data/processed/ndvi_precip_correlation.png')\n",
    "\n",
    "    # Gr√°fico: NDVI vs. Temperatura\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(merged_df['temp_mean_C'], merged_df['NDVI_mean'], color='blue', alpha=0.6)\n",
    "    plt.title('Correla√ß√£o: NDVI M√©dio vs. Temperatura M√©dia', fontsize=14)\n",
    "    plt.xlabel('Temperatura M√©dia (¬∞C)')\n",
    "    plt.ylabel('NDVI M√©dio')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('data/processed/ndvi_temp_correlation.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print('‚úì Gr√°fico salvo em data/processed/ndvi_temp_correlation.png')\n",
    "else:\n",
    "    print('‚ùå Pulando mesclagem devido a dados ausentes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Resumo da Execu√ß√£o\n",
    "\n",
    "Resumimos o status da integra√ß√£o clim√°tica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*50)\n",
    "print('üìã RESUMO DA EXECU√á√ÉO')\n",
    "print('='*50)\n",
    "if 'climate_df' in locals():\n",
    "    print(f'‚úì Setores com m√©tricas clim√°ticas: {len(climate_df)}')\n",
    "    print(f'‚úì Setores com dados v√°lidos: {len(climate_df[climate_df[[\"precip_mean_mm\", \"temp_mean_C\"]].notna().all(axis=1)])}')\n",
    "    print(f'‚úì M√©dia Precipita√ß√£o: {climate_df[\"precip_mean_mm\"].mean():.2f} mm')\n",
    "    print(f'‚úì M√©dia Temperatura: {climate_df[\"temp_mean_C\"].mean():.2f} ¬∞C')\n",
    "if 'merged_df' in locals():\n",
    "    print(f'‚úì Correla√ß√£o NDVI-Precipita√ß√£o: {correlations.loc[\"NDVI_mean\", \"precip_mean_mm\"]:.3f}')\n",
    "    print(f'‚úì Correla√ß√£o NDVI-Temperatura: {correlations.loc[\"NDVI_mean\", \"temp_mean_C\"]:.3f}')\n",
    "\n",
    "print('\\nüóÇÔ∏è ARQUIVOS GERADOS:')\n",
    "import glob\n",
    "for file in glob.glob('data/processed/*climate*.csv') + glob.glob('data/processed/*correlation*.png'):\n",
    "    if os.path.exists(file):\n",
    "        print(f'  ‚úì {file} (Tamanho: {os.path.getsize(file) / 1024 / 1024:.2f} MB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Valida√ß√£o e Instru√ß√µes\n",
    "\n",
    "- **Valida√ß√£o**:\n",
    "  - Abra `data/processed/climate_metrics.csv` para verificar as m√©tricas:\n",
    "    ```bash\n",
    "    head data/processed/climate_metrics.csv\n",
    "    ```\n",
    "  - Inspecione os gr√°ficos:\n",
    "    ```bash\n",
    "    xdg-open data/processed/ndvi_precip_correlation.png\n",
    "    xdg-open data/processed/ndvi_temp_correlation.png\n",
    "    ```\n",
    "  - Verifique coordenadas do NetCDF:\n",
    "    ```python\n",
    "    import xarray as xr\n",
    "    ds = xr.open_dataset('data/processed/data_0.nc', engine='netcdf4')\n",
    "    print(f'Latitude: {ds['latitude'].values}')\n",
    "    print(f'Longitude: {ds['longitude'].values}')\n",
    "    print(f'Num pontos: {len(ds['latitude']) * len(ds['longitude'])}')\n",
    "    ```\n",
    "- **Solu√ß√£o de Problemas**:\n",
    "  - Se alguns setores tiverem `NaN`, verifique os valores interpolados:\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('data/processed/climate_metrics.csv')\n",
    "    print(df[df[['precip_mean_mm', 'temp_mean_C']].isna().any(axis=1)])\n",
    "    ```\n",
    "  - Se necess√°rio, reexecute o download com uma bounding box maior (edite c√©lula 1):\n",
    "    ```python\n",
    "    'area': [-22.70, -47.20, -23.00, -46.90]  # Margem maior\n",
    "    ```\n",
    "    E reexecute:\n",
    "    ```bash\n",
    "    rm data/processed/data_0.nc\n",
    "    jupyter notebook climate.ipynb\n",
    "    ```\n",
    "  - Extraia `data_0.nc` do ZIP gerado e atualize `climate_path` se necess√°rio.\n",
    "- **Commit**:\n",
    "   ```bash\n",
    "   git add climate.ipynb data/processed/climate_metrics.csv data/processed/*correlation*.png\n",
    "   git commit -m \"Integra√ß√£o: corrigido tipo de CD_SETOR para merge\"\n",
    "   git push origin main\n",
    "   ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naia-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}