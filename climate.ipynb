{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integração de Dados Climáticos para o Protótipo NAIÁ\n",
    "\n",
    "Este notebook integra dados climáticos do Copernicus Climate Data Store (CDS) ao projeto NAIÁ, no contexto do Hackathon CopernicusLAC Panamá 2025 (Dia 1, 23:34, 29/07/2025, -03). O objetivo é:\n",
    "1. Baixar dados ERA5-Land (precipitação total e temperatura a 2m) para Barão Geraldo, Campinas (SP), na bounding box `[-47.15, -22.75, -46.95, -22.95]`.\n",
    "2. Agregar métricas climáticas por setor censitário usando `data/area_prova_barao.geojson`.\n",
    "3. Mesclar com métricas de Sentinel-1 e Sentinel-2 (`data/processed/metrics.csv`) para correlacionar NDVI e backscatter com variáveis climáticas.\n",
    "4. Gerar gráficos de correlação e salvar resultados em `data/processed/climate_metrics.csv`.\n",
    "\n",
    "## Configuração\n",
    "- **Ambiente**: `naia-env` (Python 3.12.7).\n",
    "- **Repositório**: `/home/lorhan/git/CorpenicusHackthon/`.\n",
    "- **Entradas**:\n",
    "  - `data/area_prova_barao.geojson`: Setores censitários.\n",
    "  - `data/processed/metrics.csv`: Métricas de NDVI e backscatter.\n",
    "  - Dados ERA5-Land via CDSAPI: `data/processed/data_0.nc` (extraído de um ZIP).\n",
    "- **Saídas**:\n",
    "  - `data/processed/climate_metrics.csv`: Métricas climáticas por setor (precipitação média, temperatura média).\n",
    "  - `data/processed/ndvi_precip_correlation.png`: Gráfico de correlação NDVI vs. precipitação.\n",
    "  - `data/processed/ndvi_temp_correlation.png`: Gráfico de correlação NDVI vs. temperatura.\n",
    "\n",
    "## Pré-requisitos\n",
    "1. Ative o ambiente: `source naia-env/bin/activate`.\n",
    "2. Instale dependências:\n",
    "   ```bash\n",
    "   pip install xarray netCDF4 cdsapi>=0.7.4 geopandas pandas numpy matplotlib scipy\n",
    "   pip freeze > requirements.txt\n",
    "   ```\n",
    "3. Configure a API CDSAPI:\n",
    "   - Crie `~/.cdsapirc` com suas credenciais do CDS ([cds.climate.copernicus.eu](https://cds.climate.copernicus.eu)):\n",
    "     ```bash\n",
    "     echo \"url: https://cds.climate.copernicus.eu/api/v2\" > ~/.cdsapirc\n",
    "     echo \"key: seu_uid:seu_api_key\" >> ~/.cdsapirc\n",
    "     ```\n",
    "4. Execute `ingest_sentinel.ipynb`, `preprocess.ipynb`, e `analyze.ipynb` para gerar `data/processed/metrics.csv`.\n",
    "5. Extraia `data_0.nc` do ZIP baixado pelo CDSAPI e coloque em `data/processed/`.\n",
    "6. Execute as células sequencialmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações\n",
    "import os\n",
    "import cdsapi\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from shapely.geometry import box\n",
    "\n",
    "# Configurar diretórios\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "print('✓ Diretório data/processed/ criado ou já existente')\n",
    "\n",
    "# Verificar versão do cdsapi\n",
    "import cdsapi\n",
    "print(f'✓ Versão do cdsapi: {cdsapi.__version__}')\n",
    "\n",
    "# Definir caminhos\n",
    "sectors_path = 'data/area_prova_barao.geojson'\n",
    "metrics_path = 'data/processed/metrics.csv'\n",
    "climate_path = 'data/processed/data_0.nc'\n",
    "output_csv = 'data/processed/climate_metrics.csv'\n",
    "\n",
    "# Verificar arquivos de entrada\n",
    "print('\\n--- Verificando arquivos de entrada ---')\n",
    "for path in [sectors_path, metrics_path]:\n",
    "    if os.path.exists(path):\n",
    "        size_mb = os.path.getsize(path) / (1024 * 1024)\n",
    "        print(f'✓ {path} ({size_mb:.1f} MB)')\n",
    "    else:\n",
    "        print(f'❌ {path} não encontrado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download de Dados Climáticos\n",
    "\n",
    "Baixamos dados ERA5-Land (precipitação total e temperatura a 2m) para a bounding box de Barão Geraldo, período de 01/06/2025 a 30/06/2025. A bounding box `[-47.15, -22.75, -46.95, -22.95]` foi validada para conter múltiplos pontos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    c = cdsapi.Client()\n",
    "    c.retrieve(\n",
    "        'reanalysis-era5-land',\n",
    "        {\n",
    "            'variable': ['total_precipitation', '2m_temperature'],\n",
    "            'year': '2025',\n",
    "            'month': '06',\n",
    "            'day': [str(i).zfill(2) for i in range(1, 31)],\n",
    "            'time': ['00:00', '06:00', '12:00', '18:00'],\n",
    "            'area': [-22.75, -47.15, -22.95, -46.95],  # [N, W, S, E]\n",
    "            'format': 'netcdf'\n",
    "        },\n",
    "        'data/processed/era5_climate.nc')\n",
    "    print(f'✓ Dados climáticos salvos em data/processed/era5_climate.nc')\n",
    "except Exception as e:\n",
    "    print(f'❌ Erro ao baixar dados ERA5-Land: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verificação de Coordenadas\n",
    "\n",
    "Inspecionamos as coordenadas do NetCDF e dos setores para confirmar cobertura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Verificar NetCDF\n",
    "    if os.path.exists(climate_path):\n",
    "        ds = xr.open_dataset(climate_path, engine='netcdf4')\n",
    "        print(f'✓ Coordenadas do NetCDF:')\n",
    "        print(f'  Latitude: {ds['latitude'].values}')\n",
    "        print(f'  Longitude: {ds['longitude'].values}')\n",
    "        print(f'  Bounding box: (min_lon, min_lat, max_lon, max_lat) = '\n",
    "              f'({ds['longitude'].min().values}, {ds['latitude'].min().values}, '\n",
    "              f'{ds['longitude'].max().values}, {ds['latitude'].max().values})')\n",
    "        print(f'  Número de pontos: {len(ds['latitude']) * len(ds['longitude'])}')\n",
    "\n",
    "        # Verificar cobertura dos setores\n",
    "        gdf = gpd.read_file(sectors_path)\n",
    "        gdf = gdf[(gdf['SITUACAO'] == 'Urbana') & (gdf['AREA_KM2'] <= 1.0)]\n",
    "        bounds = gdf.bounds\n",
    "        sectors_bbox = (bounds['minx'].min(), bounds['miny'].min(), bounds['maxx'].max(), bounds['maxy'].max())\n",
    "        print(f'\\n✓ Bounding box dos setores censitários:')\n",
    "        print(f'  (min_lon, min_lat, max_lon, max_lat) = {sectors_bbox}')\n",
    "        print(f'\\n✓ Verificação de cobertura:')\n",
    "        if (ds['longitude'].min() <= sectors_bbox[0] and ds['longitude'].max() >= sectors_bbox[2] and\n",
    "            ds['latitude'].min() <= sectors_bbox[1] and ds['latitude'].max() >= sectors_bbox[3]):\n",
    "            print('  ✓ NetCDF cobre completamente a área dos setores')\n",
    "        else:\n",
    "            print('  ⚠️ NetCDF não cobre completamente a área dos setores')\n",
    "        ds.close()\n",
    "    else:\n",
    "        print(f'❌ {climate_path} não encontrado')\n",
    "\n",
    "    # Resumo dos setores\n",
    "    print(f'\\n✓ Total de setores urbanos: {len(gdf)}')\n",
    "except Exception as e:\n",
    "    print(f'❌ Erro ao verificar coordenadas: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carregamento e Agregação por Setor\n",
    "\n",
    "Carregamos os dados climáticos e agregamos métricas (média mensal) por setor censitário, com interpolação como fallback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_climate_by_sector(climate_path, sectors_path):\n",
    "    \"\"\"Agrega dados climáticos por setor censitário.\"\"\"\n",
    "    try:\n",
    "        # Verificar arquivo NetCDF\n",
    "        if not os.path.exists(climate_path):\n",
    "            raise FileNotFoundError(f'{climate_path} não encontrado')\n",
    "        with xr.open_dataset(climate_path, engine='netcdf4') as ds:\n",
    "            print(f'✓ Arquivo {climate_path} válido, variáveis: {list(ds.variables)}')\n",
    "\n",
    "        # Carregar setores censitários\n",
    "        gdf = gpd.read_file(sectors_path)\n",
    "        gdf = gdf[(gdf['SITUACAO'] == 'Urbana') & (gdf['AREA_KM2'] <= 1.0)]\n",
    "        print(f'✓ Carregados {len(gdf)} setores urbanos')\n",
    "\n",
    "        # Carregar dados climáticos\n",
    "        ds = xr.open_dataset(climate_path, engine='netcdf4')\n",
    "        # Corrigir nomes de variáveis\n",
    "        ds['total_precipitation'] = ds['tp'] * 1000  # metros para mm\n",
    "        ds['t2m'] = ds['t2m'] - 273.15  # Kelvin para °C\n",
    "\n",
    "        # Média mensal por pixel\n",
    "        precip_mean = ds['total_precipitation'].mean(dim='valid_time')\n",
    "        temp_mean = ds['t2m'].mean(dim='valid_time')\n",
    "\n",
    "        # Configurar interpoladores\n",
    "        lat, lon = ds['latitude'].values, ds['longitude'].values\n",
    "        precip_interp = RegularGridInterpolator(\n",
    "            (lat, lon), precip_mean.values,\n",
    "            method='nearest', bounds_error=False, fill_value=np.nan\n",
    "        )\n",
    "        temp_interp = RegularGridInterpolator(\n",
    "            (lat, lon), temp_mean.values,\n",
    "            method='nearest', bounds_error=False, fill_value=np.nan\n",
    "        )\n",
    "\n",
    "        climate_metrics = []\n",
    "        sectors_with_data = 0\n",
    "        for idx, row in gdf.iterrows():\n",
    "            cd_setor = int(row['CD_SETOR'])  # Converter para int64\n",
    "            geom = row['geometry']\n",
    "            bounds = geom.bounds  # (minx, miny, maxx, maxy)\n",
    "            # Máscara ajustada para latitude decrescente\n",
    "            mask = (ds['longitude'] >= bounds[0]) & (ds['longitude'] <= bounds[2]) & \\\n",
    "                   (ds['latitude'] >= bounds[3]) & (ds['latitude'] <= bounds[1])\n",
    "            if mask.any():\n",
    "                precip = precip_mean.where(mask, drop=True).mean().values\n",
    "                temp = temp_mean.where(mask, drop=True).mean().values\n",
    "                if not np.isnan(precip) and not np.isnan(temp):\n",
    "                    sectors_with_data += 1\n",
    "                climate_metrics.append({\n",
    "                    'CD_SETOR': cd_setor,\n",
    "                    'precip_mean_mm': float(precip) if not np.isnan(precip) else np.nan,\n",
    "                    'temp_mean_C': float(temp) if not np.isnan(temp) else np.nan\n",
    "                })\n",
    "                print(f'✓ Processado setor {cd_setor}: Precip={precip:.2f} mm, Temp={temp:.2f} °C')\n",
    "            else:\n",
    "                # Fallback: usar interpolação no centróide do setor\n",
    "                centroid = geom.centroid\n",
    "                precip = precip_interp((centroid.y, centroid.x))\n",
    "                temp = temp_interp((centroid.y, centroid.x))\n",
    "                if not np.isnan(precip) and not np.isnan(temp):\n",
    "                    sectors_with_data += 1\n",
    "                climate_metrics.append({\n",
    "                    'CD_SETOR': cd_setor,\n",
    "                    'precip_mean_mm': float(precip) if not np.isnan(precip) else np.nan,\n",
    "                    'temp_mean_C': float(temp) if not np.isnan(temp) else np.nan\n",
    "                })\n",
    "                print(f'⚠️ Setor {cd_setor} fora da grade; usado interpolação: Precip={precip:.2f} mm, Temp={temp:.2f} °C')\n",
    "        print(f'\\n✓ Total de setores com dados válidos: {sectors_with_data}/{len(gdf)}')\n",
    "        climate_df = pd.DataFrame(climate_metrics)\n",
    "        climate_df['CD_SETOR'] = climate_df['CD_SETOR'].astype('int64')  # Garantir tipo int64\n",
    "        return climate_df\n",
    "    except Exception as e:\n",
    "        print(f'❌ Erro ao agregar dados climáticos: {e}')\n",
    "        return None\n",
    "\n",
    "if os.path.exists(climate_path) and os.path.exists(sectors_path):\n",
    "    print('\\n--- Agregando dados climáticos por setor ---')\n",
    "    climate_df = aggregate_climate_by_sector(climate_path, sectors_path)\n",
    "    if climate_df is not None:\n",
    "        climate_df.to_csv(output_csv, index=False)\n",
    "        print(f'✓ Métricas climáticas salvas em {output_csv}')\n",
    "else:\n",
    "    print('❌ Pulando agregação devido a arquivos ausentes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mesclagem e Correlação\n",
    "\n",
    "Mesclamos os dados climáticos com `metrics.csv` e calculamos correlações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'climate_df' in locals() and os.path.exists(metrics_path):\n",
    "    print('\\n--- Mesclando e calculando correlações ---')\n",
    "    metrics_df = pd.read_csv(metrics_path)\n",
    "    # Verificar tipos de dados\n",
    "    print(f'✓ Tipo de CD_SETOR em metrics_df: {metrics_df['CD_SETOR'].dtype}')\n",
    "    print(f'✓ Tipo de CD_SETOR em climate_df: {climate_df['CD_SETOR'].dtype}')\n",
    "    # Garantir que CD_SETOR em metrics_df seja int64\n",
    "    metrics_df['CD_SETOR'] = metrics_df['CD_SETOR'].astype('int64')\n",
    "    merged_df = metrics_df.merge(climate_df, on='CD_SETOR', how='left')\n",
    "    merged_df.to_csv(output_csv, index=False)\n",
    "    print(f'✓ Dados mesclados salvos em {output_csv}')\n",
    "\n",
    "    # Calcular correlações\n",
    "    correlations = merged_df[['NDVI_mean', 'VV_mean_dB', 'VH_mean_dB', 'precip_mean_mm', 'temp_mean_C']].corr()\n",
    "    print('\\nCorrelações:')\n",
    "    print(correlations)\n",
    "\n",
    "    # Gráfico: NDVI vs. Precipitação\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(merged_df['precip_mean_mm'], merged_df['NDVI_mean'], color='green', alpha=0.6)\n",
    "    plt.title('Correlação: NDVI Médio vs. Precipitação Média', fontsize=14)\n",
    "    plt.xlabel('Precipitação Média (mm)')\n",
    "    plt.ylabel('NDVI Médio')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('data/processed/ndvi_precip_correlation.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print('✓ Gráfico salvo em data/processed/ndvi_precip_correlation.png')\n",
    "\n",
    "    # Gráfico: NDVI vs. Temperatura\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(merged_df['temp_mean_C'], merged_df['NDVI_mean'], color='blue', alpha=0.6)\n",
    "    plt.title('Correlação: NDVI Médio vs. Temperatura Média', fontsize=14)\n",
    "    plt.xlabel('Temperatura Média (°C)')\n",
    "    plt.ylabel('NDVI Médio')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('data/processed/ndvi_temp_correlation.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print('✓ Gráfico salvo em data/processed/ndvi_temp_correlation.png')\n",
    "else:\n",
    "    print('❌ Pulando mesclagem devido a dados ausentes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Resumo da Execução\n",
    "\n",
    "Resumimos o status da integração climática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*50)\n",
    "print('📋 RESUMO DA EXECUÇÃO')\n",
    "print('='*50)\n",
    "if 'climate_df' in locals():\n",
    "    print(f'✓ Setores com métricas climáticas: {len(climate_df)}')\n",
    "    print(f'✓ Setores com dados válidos: {len(climate_df[climate_df[[\"precip_mean_mm\", \"temp_mean_C\"]].notna().all(axis=1)])}')\n",
    "    print(f'✓ Média Precipitação: {climate_df[\"precip_mean_mm\"].mean():.2f} mm')\n",
    "    print(f'✓ Média Temperatura: {climate_df[\"temp_mean_C\"].mean():.2f} °C')\n",
    "if 'merged_df' in locals():\n",
    "    print(f'✓ Correlação NDVI-Precipitação: {correlations.loc[\"NDVI_mean\", \"precip_mean_mm\"]:.3f}')\n",
    "    print(f'✓ Correlação NDVI-Temperatura: {correlations.loc[\"NDVI_mean\", \"temp_mean_C\"]:.3f}')\n",
    "\n",
    "print('\\n🗂️ ARQUIVOS GERADOS:')\n",
    "import glob\n",
    "for file in glob.glob('data/processed/*climate*.csv') + glob.glob('data/processed/*correlation*.png'):\n",
    "    if os.path.exists(file):\n",
    "        print(f'  ✓ {file} (Tamanho: {os.path.getsize(file) / 1024 / 1024:.2f} MB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validação e Instruções\n",
    "\n",
    "- **Validação**:\n",
    "  - Abra `data/processed/climate_metrics.csv` para verificar as métricas:\n",
    "    ```bash\n",
    "    head data/processed/climate_metrics.csv\n",
    "    ```\n",
    "  - Inspecione os gráficos:\n",
    "    ```bash\n",
    "    xdg-open data/processed/ndvi_precip_correlation.png\n",
    "    xdg-open data/processed/ndvi_temp_correlation.png\n",
    "    ```\n",
    "  - Verifique coordenadas do NetCDF:\n",
    "    ```python\n",
    "    import xarray as xr\n",
    "    ds = xr.open_dataset('data/processed/data_0.nc', engine='netcdf4')\n",
    "    print(f'Latitude: {ds['latitude'].values}')\n",
    "    print(f'Longitude: {ds['longitude'].values}')\n",
    "    print(f'Num pontos: {len(ds['latitude']) * len(ds['longitude'])}')\n",
    "    ```\n",
    "- **Solução de Problemas**:\n",
    "  - Se alguns setores tiverem `NaN`, verifique os valores interpolados:\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('data/processed/climate_metrics.csv')\n",
    "    print(df[df[['precip_mean_mm', 'temp_mean_C']].isna().any(axis=1)])\n",
    "    ```\n",
    "  - Se necessário, reexecute o download com uma bounding box maior (edite célula 1):\n",
    "    ```python\n",
    "    'area': [-22.70, -47.20, -23.00, -46.90]  # Margem maior\n",
    "    ```\n",
    "    E reexecute:\n",
    "    ```bash\n",
    "    rm data/processed/data_0.nc\n",
    "    jupyter notebook climate.ipynb\n",
    "    ```\n",
    "  - Extraia `data_0.nc` do ZIP gerado e atualize `climate_path` se necessário.\n",
    "- **Commit**:\n",
    "   ```bash\n",
    "   git add climate.ipynb data/processed/climate_metrics.csv data/processed/*correlation*.png\n",
    "   git commit -m \"Integração: corrigido tipo de CD_SETOR para merge\"\n",
    "   git push origin main\n",
    "   ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naia-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}